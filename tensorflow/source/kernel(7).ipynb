{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-baeef6e30cef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_notebook_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_notebook_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.tools as tls\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Loading the training data\n",
    "from kaggle.competitions import twosigmanews\n",
    "env = twosigmanews.make_env()\n",
    "(market_train_df, news_train_df) = env.get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe936bda407e82f96b1b5bebc98f918690ce8507"
   },
   "outputs": [],
   "source": [
    "# Sampling the train data data\n",
    "# Note that the data goes from 2007-02-01 to 2016-12-30\n",
    "dateFrom = '2016-08-01'\n",
    "dateTo = '2016-12-30'\n",
    "market_train_df_sample = market_train_df.loc[(dateFrom < market_train_df['time']) & (market_train_df['time'] < dateTo)]\n",
    "news_train_df_sample = news_train_df.loc[(dateFrom < news_train_df['time']) & (news_train_df['time'] < dateTo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "008c358b7917bd6725fd66e3f9a7a5b710e6d1e2"
   },
   "outputs": [],
   "source": [
    "# CLEANING MARKET DATA\n",
    "# if open price is too far from mean open price for this company, replace it. Otherwise replace close price.\n",
    "market_train_df_sample['close_to_open'] =  np.abs(market_train_df_sample['close'] / market_train_df_sample['open'])\n",
    "market_train_df_sample['assetName_mean_open'] = market_train_df_sample.groupby('assetName')['open'].transform('mean')\n",
    "market_train_df_sample['assetName_mean_close'] = market_train_df_sample.groupby('assetName')['close'].transform('mean')\n",
    "for i, row in market_train_df_sample.loc[market_train_df_sample['close_to_open'] >= 2].iterrows():\n",
    "    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n",
    "        market_train_df_sample.iloc[i,5] = row['assetName_mean_open']\n",
    "    else:\n",
    "        market_train_df_sample.iloc[i,4] = row['assetName_mean_close']\n",
    "        \n",
    "for i, row in market_train_df_sample.loc[market_train_df_sample['close_to_open'] <= 0.5].iterrows():\n",
    "    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n",
    "        market_train_df_sample.iloc[i,5] = row['assetName_mean_open']\n",
    "    else:\n",
    "        market_train_df_sample.iloc[i,4] = row['assetName_mean_close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da7b5f3076f757f12db5693e5d4f4f83a6c7a926"
   },
   "outputs": [],
   "source": [
    "# Extracting date only from date time market data\n",
    "market_train_df_sample['date'] = pd.to_datetime(market_train_df_sample['time']).progress_apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "66ee4f864fcdceea29bee7eb55a0c2a47993c8b2"
   },
   "outputs": [],
   "source": [
    "# Cleaning financial news data. Keeping only news touching the asset codes in the market data.\n",
    "# TODO: Regroup all financial news without market data in a asset code `Market`\n",
    "assetCodes = set(market_train_df_sample.assetCode.unique())\n",
    "def extractCodes(row):\n",
    "    codes = row.assetCodes.strip('{').strip('}').replace(' ','').replace(\"'\",\"\").split(',')\n",
    "    assets = []\n",
    "    for code in codes:\n",
    "        if code in assetCodes:\n",
    "            assets.append(code)\n",
    "    return assets, len(assets)\n",
    "\n",
    "def isInAsset(row):\n",
    "    if row.assetName in assetNames:\n",
    "        return True\n",
    "# Only keep row containing asset code\n",
    "news_train_df_sample['assets'], news_train_df_sample['assetsSize'] = zip(*news_train_df_sample.progress_apply(extractCodes, axis=1))\n",
    "\n",
    "# Simple approach for now: removing article where article are not related to one asset\n",
    "# Later we will create one extra asset representing the 'market'\n",
    "news_train_df_sample = news_train_df_sample[news_train_df_sample['assetsSize'] == 1]\n",
    "\n",
    "# turn asset array into single asset\n",
    "def extractElt(row):\n",
    "    return row.assets[0]\n",
    "news_train_df_sample['assetCode'] = news_train_df_sample.progress_apply(extractElt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ba5b458fcf021ec2050770dcfcaf3275cc8cb3a2"
   },
   "outputs": [],
   "source": [
    "# TODO: Feature Engineering and Dimension Reduction to be done at that point.\n",
    "# TODO: Do smoothing on Financial News ONLY here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d39591f848f713a68ab8685ab3e7d9eae5a8055a"
   },
   "outputs": [],
   "source": [
    "# Grouping financial news data by asset by date\n",
    "# Extracting date only\n",
    "news_train_df_sample['date'] = pd.to_datetime(news_train_df_sample['time']).progress_apply(lambda x: x.date())\n",
    "# Adding column to count article\n",
    "news_train_df_sample['count'] = 1\n",
    "# Grouping lines by date and asset \n",
    "# Sum number of article ( add column count = 1)\n",
    "news_train_df_sample = news_train_df_sample.groupby(['assetCode', 'date']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f3166f9059b4993fcdd9aa404de444847116c4d7"
   },
   "outputs": [],
   "source": [
    "# TODO: regularize by asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96e828481145174634306750dd0b515fd0f2f2ce"
   },
   "outputs": [],
   "source": [
    "# Indexing Market Data by date, assetCode\n",
    "market_train_df_sample = market_train_df_sample.groupby(['assetCode', 'date']).mean()\n",
    "\n",
    "# Concatenating market and news\n",
    "train_df_sample = pd.concat([market_train_df_sample, news_train_df_sample], axis=1)\n",
    "\n",
    "# We only keep line with output present (Some news day might have been weekend)\n",
    "train_df_sample = train_df_sample[train_df_sample['open'].notnull()]\n",
    "# Dropping any column where output is empty\n",
    "train_df_sample = train_df_sample.fillna(0)\n",
    "# We don't need the indexes anymore\n",
    "train_df_sample.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6622c7d70869254057c9d54b0daaa23f908796ec"
   },
   "outputs": [],
   "source": [
    "# Smoothing all the data using Exponential Moving Average\n",
    "decay = 0.5\n",
    "train_df_sample = train_df_sample.set_index('assetCode')\n",
    "numericalColumns = set(train_df_sample.columns.values)\n",
    "numericalColumns.remove('date')\n",
    "\n",
    "for asset in tqdm(assetCodes):\n",
    "    train_df_sample.loc[asset, numericalColumns] = train_df_sample.loc[asset, numericalColumns].ewm(com=decay).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b9e178c68a2d7c4c26a81a41c977db3b5f1ebbb"
   },
   "outputs": [],
   "source": [
    "# train_df_sample.head()\n",
    "market_train_df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "56fd4366ec23e094804003362898aa9f3066d2a6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating unique asset id\n",
    "def create_asset_id_dataframe(market_train_df):\n",
    "    assetId_df = market_train_df[['assetCode', 'assetName']].drop_duplicates()\n",
    "    print(\"%d unique asset codes\" % len(assetId_df))\n",
    "    assetId_df['assetName'] = assetId_df['assetName'].str.replace(' ','')\n",
    "    assetId_df['assetCodePrefix'] = assetId_df['assetCode'].apply(lambda x: x.split('.')[0])\n",
    "    assetId_df['assetId'] = np.where(assetId_df['assetName']=='Unknown', assetId_df['assetCodePrefix'], assetId_df['assetName'])\n",
    "    return assetId_df.drop_duplicates()\n",
    "\n",
    "asset_id_df = create_asset_id_dataframe(market_train_df)[['assetCode','assetId']]\n",
    "asset_id_df = asset_id_df.set_index('assetCode')\n",
    "\n",
    "%time\n",
    "train_df_sample = pd.merge(train_df_sample, asset_id_df, how='inner', left_index=True, right_index=True)\n",
    "train_df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f12b378f8fdff0936529c2cd110d5dfd3abe7630"
   },
   "outputs": [],
   "source": [
    "# Build Models\n",
    "train_df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9019cc635d6783829e31274f61ed4c3fb84b16db"
   },
   "outputs": [],
   "source": [
    "train_df_sample['assetNumber'] = train_df_sample['assetId'].astype('category').cat.codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f467e615366e12aca545d3d3489febd0474be502"
   },
   "outputs": [],
   "source": [
    "def regularizeDataPerAsset(train_df_sample, assetCodes):\n",
    "    # Regularization by asset\n",
    "    # TODO: Use another regularization technique this one will work poorly with outliers.\n",
    "    # TODO: This should return a map that will be used during forecasting...\n",
    "    train_df_sample.reset_index(inplace=True)\n",
    "    numericalColumns = set(train_df_sample.columns.values)\n",
    "    numericalColumns.remove('date')\n",
    "    numericalColumns.remove('assetCode')\n",
    "    numericalColumns.remove('assetId')\n",
    "\n",
    "    train_df_sample.set_index('assetCode', inplace=True)\n",
    "    observation = train_df_sample['returnsOpenNextMktres10']\n",
    "\n",
    "    for asset in tqdm(assetCodes):\n",
    "        df = train_df_sample.loc[asset, numericalColumns]\n",
    "        df = (df - df.mean()) / (df.max() - df.min())\n",
    "        train_df_sample.loc[asset, numericalColumns] = df\n",
    "\n",
    "    train_df_sample['nonRegularizedObservation'] = observation\n",
    "    train_df_sample.reset_index(inplace=True)\n",
    "    \n",
    "    return train_df_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "993a5d0ad0057bb94fb615025eef1f26cc430e02"
   },
   "outputs": [],
   "source": [
    "set(train_df_sample['assetCode'])\n",
    "train_df_sample = regularizeDataPerAsset(train_df_sample, list(set(train_df_sample['assetCode'])))\n",
    "# df = df.set_index('assetCode')\n",
    "# df.loc['A.N'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4aec387995466a24cbbd3e6bb8a4fb3e23409740"
   },
   "outputs": [],
   "source": [
    "# train_df_sample.head()\n",
    "numericalColumns = set(train_df_sample.columns.values)\n",
    "numericalColumns.remove('date')\n",
    "numericalColumns.remove('assetId')\n",
    "assets = np.unique(train_df_sample.index.values)\n",
    "\n",
    "df = train_df_sample.loc[assets, numericalColumns]\n",
    "abs_max_df = df.abs().groupby('assetCode').max()\n",
    "min_df = df.groupby('assetCode').min()\n",
    "mean_df = df.groupby('assetCode').mean()\n",
    "std_df = df.groupby('assetCode').std()\n",
    "\n",
    "for asset in tqdm(assets):\n",
    "    df.loc[asset] = df.loc[asset] / abs_max_df.loc[asset]\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6d7f7a1abbcd97c1395d9831efb786511951637"
   },
   "outputs": [],
   "source": [
    "norm_train_df = pd.DataFrame(train_df_sample)\n",
    "for asset in tqdm(assets):\n",
    "    norm_train_df.loc[asset, numericalColumns] = df.loc[asset, numericalColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "886810f27db0fb97f7c0b573834ffdba1e0fa59a"
   },
   "outputs": [],
   "source": [
    "norm_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "139460870801ca225e30bc621be2a86cb30bb34f"
   },
   "outputs": [],
   "source": [
    "train_df_sample = train_df_sample.reset_index()\n",
    "train_df_sample = train_df_sample.sort_values(by=['date'])\n",
    "labels = train_df_sample['returnsOpenNextMktres10']\n",
    "non_numeric = train_df_sample[['returnsOpenNextMktres10','assetCode','date','assetId']]\n",
    "train = train_df_sample.drop(['returnsOpenNextMktres10','assetCode','date','assetId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "194963d426cd83e485c0f9b55f98174d013e163a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_df_sample.head()\n",
    "# non_numeric.head()\n",
    "# train.head()\n",
    "# len(train.columns)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "54f548443dfe814592afe372725ead7617c53033"
   },
   "outputs": [],
   "source": [
    "train = norm_train_df.sort_values(by=['date'])\n",
    "train = train.fillna(0)\n",
    "labels = train['returnsOpenNextMktres10']\n",
    "train = train.drop(['returnsOpenNextMktres10','date','assetId'], axis=1)\n",
    "train.isna().sum()\n",
    "labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b10c37b4e1bb3fb8b9d376be00d73ba58853fa21"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be09b2a34b360d9462aa6197694f73e08f3e7fec",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model construction and training. Single layer NN\n",
    "model = keras.Sequential([keras.layers.Dense(100, activation=tf.nn.relu, input_shape=(len(train.columns),)), \n",
    "#                           keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "                         keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.fit(train, labels, epochs=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f4b71f6ad2c03730afae84a1b310cdba58a256c5"
   },
   "outputs": [],
   "source": [
    "# predictions = model.predict(train.head())\n",
    "predictions = model.predict(train)\n",
    "# np.argmax(predictions[1])\n",
    "# np.apply_along_axis(np.argmax, 1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1360a012e376f58b7a39fa0c1504f19a6ecf31b0"
   },
   "outputs": [],
   "source": [
    "# predictions.mean()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e4d7077493f8f679a372ce1d5cfc2cab27baa96"
   },
   "outputs": [],
   "source": [
    "def evaluate(df):\n",
    "    df['yr'] = df.apply(lambda row: row.returnsOpenNextMktres10 * row.pred, axis=1)\n",
    "    df[['date','yr']].groupby(['date']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "599bbcf700ffb93d65c2033e0011429495615a67"
   },
   "outputs": [],
   "source": [
    "train_df_sample = train_df_sample.sort_values(by=['date'])\n",
    "score_df = train_df_sample[['date','returnsOpenNextMktres10']]\n",
    "score_df['pred'] = predictions\n",
    "score_df['yr'] = score_df.apply(lambda row: row.returnsOpenNextMktres10 * row.pred, axis=1)\n",
    "\n",
    "score_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e92028d2f918558faf548be1031fcef32cabb926"
   },
   "outputs": [],
   "source": [
    "sum_score = score_df[['date','yr']].groupby(['date']).sum()\n",
    "final_score = sum_score['yr'].mean() / sum_score['yr'].std()\n",
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b88d28d5887b6084032692ba1add78420aaaa13"
   },
   "outputs": [],
   "source": [
    "score_df[['date','yr']].groupby(['date']).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
